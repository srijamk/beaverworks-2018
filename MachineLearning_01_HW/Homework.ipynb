{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from student import NearestNeighbor, load_cifar10, validate_shapes\n",
    "from subprocess import Popen\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Training data shape: ', x_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for label_ind, cls in enumerate(classes):\n",
    "    idxs = np.where(y_train == label_ind)[0]\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + label_ind + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(x_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets use a small fraction of the data to speed up our code development\n",
    "x_train, y_train = x_train[:5000], y_train[:5000]\n",
    "x_test, y_test = x_test[:500], y_test[:500]\n",
    "print('Training data shape: ', x_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finally, let's reshape each data point into a single vector\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], -1))\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Open up `student.py` and write code that fills the specifications in `compute_distances`. Your code will be called like this\n",
    "```python\n",
    "classifier = NearestNeighbor()\n",
    "classifier.train(x_train, y_train)  # This just remembers all of the samples\n",
    "dists = classifier.compute_distances(X)  # X is an (N x 3072) numpy array\n",
    "```\n",
    "Your ouput should have the following properties\n",
    "* `dists` is a `np.array` with shape `(X.shape[0], x_train.shape[0])`\n",
    "* `dists[i, j]` = the L2 distance between `X[i]` and `x_train[j]`\n",
    "* `compute_distances` _avoids_ using two explicit loops to calculate this distance (it's very slow), instead opting for at least a one-loop implementation as demonstrated in the reading. In Python module 4, you will compute this distance in a vectorized way with _no_ explicit loops, which is very fast.\n",
    "* `compute_distances` should work for arbitrary `x_train` and `X`, as long as they have the same number of columns (i.e. you should _not_ explicitly require 3072 columns in your implementation)\n",
    "\n",
    "** Use the output of the cell below to answer question 1 of the homework **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python grade_compute_distances.pyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Let's use `x_test` to examine the output of `compute_distances`.\n",
    "\n",
    "** Use the output of the cells below to answer question 2 of the homework **\n",
    "\n",
    "NOTE: Question 2 has multiple parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = NearestNeighbor()\n",
    "classifier.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dists = classifier.compute_distances(x_test)\n",
    "plt.imshow(dists, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Open up `student.py` and write code that fills the specifications in `predict`. Your code will be called like this\n",
    "```python\n",
    "classifier = NearestNeighbor()\n",
    "classifier.train(x_train, y_train)\n",
    "pred = classifier.predict(X, k=5)\n",
    "```\n",
    "Your code should have the following characteristics\n",
    "* If `X` is an MxN array, `pred` is an array of M labels\n",
    "* For each image in `X`, the `k` nearest neighbors should vote on the label (the label with the most votes wins)\n",
    "* If there is a tie, the _smallest_ of the tied labels should win\n",
    "\n",
    "** Strategies **\n",
    "* Divide your work into manageable chunks -- we recommend the following approach\n",
    "  * Use your `compute_distances` function to find the k nearest neighbors to each image in X (look into [np.argsort](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html))\n",
    "  * Use `self.ytr` to get the labels of those neighbors\n",
    "  * For each image, find the most frequent value among those labels & apply the tie-breaking rule listed above\n",
    "* Test your approach on smaller data\n",
    "  * `np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])` is a perfectly good example\n",
    "  * Create a new classifier with a small dataset using `new_classifier = NearestNeighbor(); new_classifier.train(new_x, new_y)`\n",
    "\n",
    "** Use the output from the cell below to answer question 3 of the homework **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python grade_predictions.pyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 - Choosing Hyperparameters\n",
    "Hyperparameters are distinguished from \"normal\" parameters in machine learning because they are never _optimized_ numerically during training. Instead, they are set manually by the engineer who is training the model. However, this does not imply that you should choose hyperparameters without any sort of method. You are about to demonstrate one of the most common methods for choosing hyperparameters: _cross validation_.\n",
    "\n",
    "In cross validation, segments of the training data are temporarily separated for intermediate \"testing\" of the hyperparameter selection. The hyperparameters that perform the best across all \"folds\" of the training data are then selected for the final evaluation on the test data.\n",
    "\n",
    "The k-nearest-neighbor has a single hyperparameter, _k_, which we will now set using cross validation.\n",
    "\n",
    "Feel free to use the utility function `validate_shapes` to make sure you're creating your folds correctly.\n",
    "\n",
    "### NOTE\n",
    "You _can_ complete this section after having only read the K-nearest neighbors reading material, however, it will run very slow. If you are impatient please read Python Module 4 (Advanced NumPy), particularly the section on broadcasting and distance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
    "frac = x_train.shape[0]//num_folds\n",
    "x_train_folds = [x_train[i*frac:(i+1)*frac] for i in range(num_folds)]\n",
    "y_train_folds = [y_train[i*frac:(i+1)*frac] for i in range(num_folds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracies = dict()\n",
    "for k in k_choices:\n",
    "    print('k = {}'.format(k))\n",
    "    accuracies[k] = list()\n",
    "    for i in range(num_folds):\n",
    "        # STUDENT CODE GOES HERE\n",
    "        # Create x_train_fold, y_train_fold, x_val_fold and y_val_fold\n",
    "        # for num_folds == 5\n",
    "        #    x_train_fold.shape = (4000, 3072)\n",
    "        #    y_train_fold.shape = (4000,)\n",
    "        #    x_val_fold.shape = (1000, 3072)\n",
    "        #    y_val_fold.shape = (1000,)\n",
    "        # \n",
    "        # HINT: Look at the documentation for numpy.vstack\n",
    "        pass\n",
    "        \n",
    "        # Optional\n",
    "        # validate_shapes(x_train_fold, y_train_fold, x_val_fold, y_val_fold)\n",
    "        \n",
    "        # STUDENT CODE GOES HERE\n",
    "        # Evaluate the accuracy of your classifier, trained with x_train_fold and\n",
    "        # tested on x_val_fold. Append the accuracy (0.00 <= acc <= 1.00) to accuracies[k]\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the cell below, you should see a plot that looks an awful lot like the [example from the required reading](https://cs231n.github.io/classification/) (towards the bottom of the text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in k_choices:\n",
    "    plt.scatter([k] * len(accuracies[k]), accuracies[k])\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(accuracies.items())])\n",
    "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use this output to answer the rest of the questions in the homework **"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
